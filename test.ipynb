{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 261,
   "source": [
    "from lark import Lark\n",
    "json_parser = Lark(r\"\"\"\n",
    "    ?value: dict\n",
    "         | list\n",
    "         | string\n",
    "         | number\n",
    "         | \"true\"          -> true\n",
    "         | \"false\"         -> false\n",
    "         | \"null\"          -> null\n",
    "\n",
    "    list : \"[\" [value (\",\" value)*] \"]\"\n",
    "\n",
    "    dict : \"{\" [pair (\",\" pair)*] \"}\"\n",
    "    pair : string \":\" value\n",
    "\n",
    "    number : /-?\\d+(\\.\\d+)?([eE][+-]?\\d+)?/\n",
    "    string : /\".*?(?<!\\\\)\"/\n",
    "\n",
    "    %ignore /[ \\t\\n\\f\\r]+/\n",
    "\n",
    "    \"\"\", start='value', lexer='standard')\n",
    "text = '[[\"LL1\", \"LR1\"],[\"RL1\", \"RR1\"]]'\n",
    "test_json = '''\n",
    "    {\n",
    "        \"empty_object\" : {},\n",
    "        \"empty_array\"  : [],\n",
    "        \"booleans\"     : { \"YES\" : true, \"NO\" : false },\n",
    "        \"numbers\"      : [ 0, 1, -2, 3.3, 4.4e5, 6.6e-7 ],\n",
    "        \"strings\"      : [ \"This\", [ \"And\" , \"That\", \"And a \\\\\"b\" ] ],\n",
    "        \"nothing\"      : null\n",
    "    }\n",
    "'''"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "source": [
    "from lark import Transformer\n",
    "\n",
    "class MyTransformer(Transformer):\n",
    "    def list(self, items):\n",
    "        print(items)\n",
    "        return list(items)\n",
    "    def pair(self, key_value):\n",
    "        k, v = key_value\n",
    "        return k, v\n",
    "    def dict(self, items):\n",
    "        return dict(items)\n",
    "    def string(self, s):\n",
    "        (s,) = s\n",
    "        print(s)\n",
    "        return s[1:-1]\n",
    "    def number(self, n):\n",
    "        (n,) = n\n",
    "        return float(n)\n",
    "    null = lambda self, _: None\n",
    "    true = lambda self, _: True\n",
    "    false = lambda self, _: False\n",
    "tree = json_parser.parse(text)\n",
    "a = MyTransformer().transform(tree)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\"LL1\"\n\"LR1\"\n['LL1', 'LR1']\n\"RL1\"\n\"RR1\"\n['RL1', 'RR1']\n[['LL1', 'LR1'], ['RL1', 'RR1']]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "assign_var\n  a\n  add\n    sub\n      number\t1\n      number\t1\n    number\t1\n\n"
     ]
    }
   ],
   "source": [
    "print(tree.pretty())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 676,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "aaa\naaa\naaa\naaa\n"
     ]
    }
   ],
   "source": [
    "parser = Lark(r\"\"\"\n",
    "\n",
    "start: WS? line (WS_NEWLINE line)* WS?\n",
    "\n",
    "line: LINE  \n",
    "\n",
    "\n",
    "LINE.1: \"aaa\"\n",
    "\n",
    "WS: (WS_INLINE | COMMENT | WS_NEWLINE)+\n",
    "\n",
    "WS_INLINE.1: /[ \\t]+/ \n",
    "COMMENT.2:  /\\/\\/.*/                      \n",
    "WS_NEWLINE.3: (WS_INLINE|COMMENT)* /[\\r\\n]/ (WS_INLINE|COMMENT)*\n",
    "\n",
    "%ignore WS  \n",
    "%ignore COMMENT           \n",
    "%ignore WS_NEWLINE\n",
    "\n",
    "\"\"\",  lexer=\"standard\", keep_all_tokens=False)\n",
    "mytree = parser.lex(\"\"\"\n",
    "// kdfjk\n",
    "aaa// kdfjk\n",
    " aaa    // kjfj\n",
    "aaa \n",
    "\n",
    "   aaa\n",
    "   \n",
    "\"\"\")\n",
    "\n",
    " \n",
    "for token in mytree:\n",
    "    print(str(token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 677,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "A\n"
     ]
    }
   ],
   "source": [
    "parser = Lark(r\"\"\"\n",
    "\n",
    "start: A B?\n",
    "\n",
    "A: /.+/\n",
    "B.4: /b+/\n",
    "\n",
    "\"\"\",  lexer=\"standard\", keep_all_tokens=False)\n",
    "mytree = parser.lex(\"\"\"abbb\"\"\")\n",
    "\n",
    " \n",
    "for token in mytree:\n",
    "    print(token.type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "foo\nbar\n"
     ]
    }
   ],
   "source": [
    "print(bytes(r\"foo\\nbar\", \"utf-8\").decode(\"unicode_escape\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "xx\n"
     ]
    }
   ],
   "source": [
    "a = \"\\n\\nxx\\n\\n\"\n",
    "print(a.strip())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 682,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Token('xx', 'NAME')"
      ]
     },
     "metadata": {},
     "execution_count": 682
    }
   ],
   "source": [
    "a =  lark.Token(\"NAME\", \"xx\")\n",
    "a.update(\"xx\", \"NAME\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.8"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}